{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7913fae",
   "metadata": {},
   "source": [
    "# Ch6 exercises: Linear model selection and regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0058924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import itertools\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f780e124",
   "metadata": {},
   "source": [
    "<b> 8a) Use the rnorm() function to generate a predictor X of length n = 100, as well as a noise vector ε of length n = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c7cc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting n to 100 for use later\n",
    "n = 100\n",
    "\n",
    "# generating a predictor, X, using numpy's random.normal function\n",
    "X = np.random.normal(size=n)\n",
    "\n",
    "# generating a noise vector, E, using numpy's random.normal function\n",
    "E = np.random.normal(size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b042b0",
   "metadata": {},
   "source": [
    "<b> 8b) Generate a response vector Y of length n = 100 according to the model:\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\epsilon\n",
    "$$\n",
    "\n",
    "<b> where β0, β1, β2, and β3 are constants of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a90811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining constant values\n",
    "constant_0 = 1.5 \n",
    "constant_1 = 2.0\n",
    "constant_2 = 0.5\n",
    "constant_3 = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1064d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Y\n",
    "Y = constant_0 + constant_1*X + constant_2*X**2 + constant_2*X**2 + constant_2*X**3 + E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9cbe205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.17632977e+00  7.54289411e-01  2.36540559e+01  5.32939209e+00\n",
      "  3.98861242e-01  1.00561144e+00  1.74896431e+00  2.09077944e+01\n",
      " -1.89421903e+00 -2.20231267e+00  1.26711024e+00  1.32366835e+00\n",
      "  4.21104450e+00  1.04447124e+00  1.08640319e+00  2.33767880e+00\n",
      "  2.83565255e+00 -1.93748408e-01  1.27433916e-01  1.90952988e+01\n",
      "  3.92050205e+00  4.95091697e-02  1.39940553e+01 -1.58364965e-01\n",
      "  2.63748073e+00  4.41160730e+00  3.03183412e+00  1.90768614e+00\n",
      " -3.07171128e+00 -2.74201834e-01  5.91896664e+00 -4.68120109e-01\n",
      "  3.29509279e+00  7.65453356e-01  3.61426434e+00  1.24663761e+01\n",
      "  2.37783112e+00  4.69151487e+00  3.86870271e+00  8.08448404e+00\n",
      "  1.59301766e+00 -4.04399209e+00  3.01101593e+00  2.67119307e+00\n",
      "  3.47390570e-01 -1.57391215e+00 -1.65188471e+00  7.57614489e+00\n",
      "  1.48295117e+00  1.16559769e+00  6.52148167e-01 -3.17848387e+00\n",
      "  2.44489176e+00 -3.79224949e-01  1.37849358e+00  1.39814149e+00\n",
      "  2.46532658e+00 -2.16935710e+00  1.45822083e+00 -1.10849511e-01\n",
      "  3.32679275e+00  8.51891919e-01 -2.18540257e+00  1.02622093e+00\n",
      " -4.77978854e-01  5.00428594e+00 -1.95566974e+00 -1.12975869e+00\n",
      "  1.25534549e+00  1.71906043e+00  1.84567279e+00  1.48540459e+00\n",
      "  6.74319911e-01  2.06251432e+00  4.00559988e+00  9.13870665e+00\n",
      " -8.58452120e+00 -4.71720049e-01  9.38103350e-03  7.25714757e-01\n",
      "  3.39137579e+00  8.50781624e+00  2.39296406e+00  5.14949012e+00\n",
      "  6.77623734e-01  2.60332233e+00  3.54783900e-01  7.10085906e+00\n",
      "  3.45253362e+00  2.12359606e-01  1.77489760e+00  1.13397962e+01\n",
      "  1.17318713e+00  1.70404652e+00 -2.46083913e+00 -1.65059723e+00\n",
      " -9.51770050e-01  2.41835357e+00  6.41326524e-01  8.36268641e-01]\n"
     ]
    }
   ],
   "source": [
    "# seeing what Y looks like\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bd74e",
   "metadata": {},
   "source": [
    "<b>8c) Perform best subset selection in order to choose the best model containing the predictors X,X2,...,X10. What is the best model obtained according to Cp, BIC, and adjusted R2? Show some plots to provide evidence for your answer, and report the coefficients of the best model obtained. <u>Note you will need to create a single data set containing both X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff8735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe with X and Y\n",
    "df = pd.DataFrame({'X': X, 'Y': Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8400376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X          Y\n",
      "0  -1.266366  -1.176330\n",
      "1  -0.306700   0.754289\n",
      "2   2.672383  23.654056\n",
      "3   0.973636   5.329392\n",
      "4   0.046181   0.398861\n",
      "..       ...        ...\n",
      "95 -1.325153  -1.650597\n",
      "96 -0.640027  -0.951770\n",
      "97 -0.091344   2.418354\n",
      "98 -0.485894   0.641327\n",
      "99 -1.004008   0.836269\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90e481c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating from 2 to 10 and generating powers of X from X^2 to X^10 by adding new columns to df\n",
    "for i in range(2, 11):\n",
    "    df[f'X^{i}'] = df['X'] ** i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c2e92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising variables to store the best models according to Cp, BIC, and adjusted R^2\n",
    "best_model_cp = None\n",
    "best_model_bic = None\n",
    "best_model_r2adj = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54ac61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a loop to iterate over all possible subset sizes k (from 1 to the number of predictors) and generate all combinations of predictors of size k\n",
    "for k in range(1, len(predictors) + 1):\n",
    "    subsets = itertools.combinations(predictors, k)\n",
    "    \n",
    "    for subset in subsets:\n",
    "        subset = list(subset)\n",
    "        \n",
    "        model = sm.GLS(df['Y'], sm.add_constant(df[subset])).fit()\n",
    "        \n",
    "        if best_model_cp is None or model.aic < best_model_cp.aic:\n",
    "            best_model_cp = model\n",
    "        if best_model_bic is None or model.bic < best_model_bic.bic:\n",
    "            best_model_bic = model\n",
    "        if best_model_r2adj is None or model.rsquared_adj > best_model_r2adj.rsquared_adj:\n",
    "            best_model_r2adj = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "676f496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model according to Cp:\n",
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.961\n",
      "Model:                            GLS   Adj. R-squared:                  0.959\n",
      "Method:                 Least Squares   F-statistic:                     781.5\n",
      "Date:                Fri, 26 May 2023   Prob (F-statistic):           2.75e-67\n",
      "Time:                        15:14:04   Log-Likelihood:                -134.34\n",
      "No. Observations:                 100   AIC:                             276.7\n",
      "Df Residuals:                      96   BIC:                             287.1\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5669      0.115     13.668      0.000       1.339       1.794\n",
      "X              2.1570      0.163     13.225      0.000       1.833       2.481\n",
      "X^2            0.9662      0.056     17.362      0.000       0.856       1.077\n",
      "X^3            0.4791      0.037     13.069      0.000       0.406       0.552\n",
      "==============================================================================\n",
      "Omnibus:                        5.275   Durbin-Watson:                   1.954\n",
      "Prob(Omnibus):                  0.072   Jarque-Bera (JB):                4.757\n",
      "Skew:                           0.522   Prob(JB):                       0.0927\n",
      "Kurtosis:                       3.232   Cond. No.                         8.51\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# printing summaries of the best models\n",
    "print(\"Best model according to Cp:\")\n",
    "print(best_model_cp.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fa89729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model according to BIC:\n",
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.961\n",
      "Model:                            GLS   Adj. R-squared:                  0.959\n",
      "Method:                 Least Squares   F-statistic:                     781.5\n",
      "Date:                Fri, 26 May 2023   Prob (F-statistic):           2.75e-67\n",
      "Time:                        15:14:14   Log-Likelihood:                -134.34\n",
      "No. Observations:                 100   AIC:                             276.7\n",
      "Df Residuals:                      96   BIC:                             287.1\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5669      0.115     13.668      0.000       1.339       1.794\n",
      "X              2.1570      0.163     13.225      0.000       1.833       2.481\n",
      "X^2            0.9662      0.056     17.362      0.000       0.856       1.077\n",
      "X^3            0.4791      0.037     13.069      0.000       0.406       0.552\n",
      "==============================================================================\n",
      "Omnibus:                        5.275   Durbin-Watson:                   1.954\n",
      "Prob(Omnibus):                  0.072   Jarque-Bera (JB):                4.757\n",
      "Skew:                           0.522   Prob(JB):                       0.0927\n",
      "Kurtosis:                       3.232   Cond. No.                         8.51\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model according to BIC:\")\n",
    "print(best_model_bic.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17d04dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model according to adjusted R^2:\n",
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.963\n",
      "Model:                            GLS   Adj. R-squared:                  0.960\n",
      "Method:                 Least Squares   F-statistic:                     341.6\n",
      "Date:                Fri, 26 May 2023   Prob (F-statistic):           6.29e-63\n",
      "Time:                        15:14:22   Log-Likelihood:                -131.34\n",
      "No. Observations:                 100   AIC:                             278.7\n",
      "Df Residuals:                      92   BIC:                             299.5\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5510      0.171      9.055      0.000       1.211       1.891\n",
      "X              2.0542      0.195     10.552      0.000       1.668       2.441\n",
      "X^2            1.7141      0.832      2.060      0.042       0.062       3.366\n",
      "X^3            0.5420      0.061      8.835      0.000       0.420       0.664\n",
      "X^4           -1.3990      0.896     -1.562      0.122      -3.178       0.380\n",
      "X^6            0.6516      0.348      1.874      0.064      -0.039       1.342\n",
      "X^8           -0.1087      0.054     -2.000      0.048      -0.217      -0.001\n",
      "X^10           0.0059      0.003      2.038      0.044       0.000       0.012\n",
      "==============================================================================\n",
      "Omnibus:                        5.433   Durbin-Watson:                   2.015\n",
      "Prob(Omnibus):                  0.066   Jarque-Bera (JB):                4.773\n",
      "Skew:                           0.486   Prob(JB):                       0.0919\n",
      "Kurtosis:                       3.448   Cond. No.                     7.15e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.15e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model according to adjusted R^2:\")\n",
    "print(best_model_r2adj.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dcb3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the coefficients of the best models\n",
    "best_model_cp_coeffs = best_model_cp.params\n",
    "best_model_bic_coeffs = best_model_bic.params\n",
    "best_model_r2adj_coeffs = best_model_r2adj.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad5de284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of the best model according to Cp:\n",
      "const    1.566936\n",
      "X        2.157003\n",
      "X^2      0.966199\n",
      "X^3      0.479067\n",
      "dtype: float64\n",
      "Coefficients of the best model according to BIC:\n",
      "const    1.566936\n",
      "X        2.157003\n",
      "X^2      0.966199\n",
      "X^3      0.479067\n",
      "dtype: float64\n",
      "Coefficients of the best model according to adjusted R^2:\n",
      "const    1.551008\n",
      "X        2.054153\n",
      "X^2      1.714072\n",
      "X^3      0.542002\n",
      "X^4     -1.399001\n",
      "X^6      0.651574\n",
      "X^8     -0.108679\n",
      "X^10     0.005917\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# printing summaries of the coefficients according to the best models\n",
    "print(\"Coefficients of the best model according to Cp:\")\n",
    "print(best_model_cp_coeffs)\n",
    "\n",
    "print(\"Coefficients of the best model according to BIC:\")\n",
    "print(best_model_bic_coeffs)\n",
    "\n",
    "print(\"Coefficients of the best model according to adjusted R^2:\")\n",
    "print(best_model_r2adj_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1c152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
